* 
:properties:
:author: Ms. M. Saritha and Ms. S. Rajalakshmi
:date: 15-03-2021
:end:

#+startup: showall
{{{title-tab}}}
| CODE    | COURSE TITLE                         | L | T | P | E | C |
| UCS2735 | PRINCIPLES OF REINFORCEMENT LEARNING | 3 | 0 | 0 | 0 | 3 |


** COURSE OBJECTIVES
- To understand the basics of reinforcement learning techniques
- To explore various methods used in reinforcement learning
- To apply reinforcement learning techniques for various case studies.

{{{unit}}}
| UNIT I | INTRODUCTION | 9 |
Reinforcement Learning -- Examples -- Elements of Reinforcement
Learning -- Limitations and Scope -- Tic-Tac-Toe; Multi-armed Bandits;
Finite Markov Decision Processes.

{{{unit}}}
| UNIT II | TABULAR SOLUTION METHODS | 11 |
Dynamic Programming; Monte Carlo Methods: Prediction -- Estimation of
Action Values -- Control -- Control without Exploring Starts --
Off-policy Prediction via Importance Sampling -- Incremental
Implementation -- Off-policy Monte Carlo Control; Temporal-Difference
Learning.

{{{unit}}}
| UNIT III |  INTEGRATION OF TABULAR METHODS | 9 |
n-step Bootstrapping: TD Prediction -- Sarsa -- Off-policy Learning;
Planning and Learning with Tabular Methods.

{{{unit}}}
| UNIT IV | APPROXIMATE SOLUTION METHODS | 10 |
On-policy Prediction with Approximation; On-policy Control with
Approximation; Eligibility Traces: The \lambda-return -- TD(\lambda)
-- n-step Truncated \lambda-return Methods -- Online \lambda-return
Algorithm -- True Online TD(\lambda); Policy Gradient Methods.

{{{unit}}}
| UNIT V | APPLICATIONS AND CASE STUDIES | 6 |
TD-Gammon; Watsonâ€™s Daily-Double Wagering; Optimizing Memory Control;
Human-level Video Game Play.

\hfill *Total Periods: 45*

** COURSE OUTCOMES
After the completion of this course, students will be able to 
1. Illustrate the basics of reinforcement learning problem (K2)
2. Solve various problems using tabular solution methods (K3)
3. Apply the integrated tabular methods for problem solutions (K3)
4. Illustrate approximate solution methods for larger state space
   problems (K2)
5. Apply reinforcement learning techniques for various case studies
   (K3).

** TEXT BOOKS
1. Richard S Sutton & Andrew G. Barto, ``Reinforcement Learning: An
   Introduction'', The MIT Press, 2nd Edition, 2018.
2. Marco Wiering, Martijn van Otterlo, ``Reinforcement Learning
   State-of-the-Art'', Springer, 2012.

** REFERENCES
1.  Boris Belousov, Hany Abdulsamad, Pascal Klink, Simone Parisi & Jan
   Peters, ``Reinforcement Learning Algorithms: Analysis and
   Applications'', Springer, 1st edition, 2021.
2.  Micheal Lanham, ``Hands-On Reinforcement Learning for Games'',
   Packt Publishing Ltd., 2020.
3.  Taweh Beysoloqw II, ``Applied Reinforcement Learning with Python'', Apress, 2019.
4.  Dimitri Bertsekas, ``Reinforcement Learning and Optimal Control'',
   Athena Scientific, 2019.

** CO TO PO/PSO MAPPING
 
| PO/PSO | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | 11 | 12 | 1 | 2 | 3 |
|--------+---+---+---+---+---+---+---+---+---+----+----+----+---+---+---|
| CO1    | 2 | 1 | 1 | 1 | 0 | 0 | 0 | 0 | 0 |  1 |  0 |  0 | 1 | 0 | 0 |
| CO2    | 3 | 3 | 3 | 3 | 0 | 0 | 0 | 0 | 0 |  1 |  0 |  2 | 2 | 0 | 1 |
| CO3    | 3 | 3 | 3 | 3 | 0 | 0 | 0 | 0 | 0 |  1 |  0 |  2 | 2 | 0 | 1 |
| CO4    | 2 | 3 | 2 | 1 | 0 | 0 | 0 | 0 | 0 |  1 |  0 |  0 | 2 | 0 | 0 |
| CO5    | 3 | 3 | 3 | 3 | 1 | 0 | 0 | 0 | 3 |  1 |  0 |  2 | 1 | 0 | 2 |
|--------+---+---+---+---+---+---+---+---+---+----+----+----+---+---+---|
| Course | 3 | 3 | 3 | 3 | 1 | 0 | 0 | 0 | 1 |  1 |  0 |  2 | 2 | 0 | 1 |

# | Score | 13 | 13 | 12 | 11 | 1 | 0 | 0 | 0 | 3 | 5 | 0 | 6 | 8 | 0 | 4 |
   
