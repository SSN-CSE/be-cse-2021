* 
:properties:
:author: Dr.R.S.Milton, Ms.S.Rajalakshmi
:date: 29.3.21
:end:

#+startup: showall
{{{title-tab}}}
| CODE    | COURSE TITLE                   | L | T | P | C |
| UCS2623 | PROBABILISTIC GRAPHICAL MODELS | 3 | 0 | 0 | 3 |

#+begin_comment
co-po mapping added
soft po added
#+end_comment

** R2021 CHANGES :noexport:
New Subject

** COURSE OBJECTIVES
- To learn the key aspects of directed and undirected models
- To apply the techniques to represent the model, do inference and learning
- To understand the methods for learning in hidden data.
#+begin_comment

#+end_comment

{{{unit}}}
|UNIT I | INTRODUCTION| 9 |
Probabilistic Reasoning: Conditional Probability -- Probability Tables
-- Prior, Likelihood and Posterior; Graph Concept; Belief Networks:
Benefits of structure -- Uncertain and Unreliable Evidence -- Belief
concepts -- Causality.

{{{unit}}}
|UNIT II | REPRESENTATION IN GRAPHICAL MODELS | 9 |
Bayesian Network Representation: Independence properties --
Independence in graphs -- From distributions to graphs; Undirected
Graphical Models: Parameterization -- Markov Network Independencies --
Bayesian networks and Markov networks -- Partially directed models.

{{{unit}}}
|UNIT III | INFERENCE IN GRAPHICAL MODELS | 9 |
Efficient Inference in Trees: Marginal Inference -- Forms of Inference
-- Inference in Multiply Connected Graphs; Junction Tree Algorithm:
Clustering variables -- Clique graphs -- Junction trees --
Constructing junction trees for singly-Connected Distributions --
Junction Trees for Multiply-Connected Distributions -- Junction Tree
Algorithm; Making Decisions: Expected Utility -- Extending Bayesian
Networks for Decisions -- Solving Influence Diagrams -- Markov
Decision Processes -- Variational Inference and Planning.

{{{unit}}}
|UNIT IV | LEARNING IN PROBABILISTIC MODELS | 9 |
Statistics for Machine Learning: Representing Data -- Distributions --
Multivariate Gaussian -- Conjugate priors -- Properties of Maximum
Likelihood -- Learning a Gaussian; Learning as Inference: Bayesian
methods -- Maximum Likelihood Training of Belief Networks -- Bayesian
Belief Network Training -- Structure learning -- Maximum Likelihood
for Undirected models; Naive Bayes: Conditional Independence --
Estimation using Maximum Likelihood -- Bayesian Naive Bayes -- Tree
Augmented Naive Bayes.

{{{unit}}}
|UNIT V | LEARNING IN HIDDEN ENVIRONMENT | 9 |
Learning with Hidden Variables: Hidden Variables and Missing Data --
Expectation Maximisation -- Extensions of EM -- Variational Bayes;
Bayesian Model Selection: Comparing Models the Bayesian Way -- Occamâ€™s
Razor and Bayesian Complexity Penalisation -- Approximating the Model
Likelihood -- Bayesian Hypothesis Testing for Outcome Analysis.


** COURSE OUTCOMES
Upon completion of the course, the student should be able to:
- Explain the need for probabilistic graphical models (K2)
- Apply and analyze the various representations like directed and undirected models (K3)
- Select the inference algorithms to analyze the models  (K3)
- Apply the learning techniques to learn the structure and parameter in models (K3)
- Identify the learning techniques for hidden data (K2)
- Solve a real time problem using any probabilistic graphical models in teams (K3).
      
** TEXT BOOKS
1. David Barber, ``Bayesian Reasoning and Machine Learning'',
   Cambridge University Press, 2020. 
2. Daphne Koller, Nir Friedman, ``Probabilistic Graphical Models -
   Principles and Technique'', MIT Press, 2007. 

** REFERENCES
1. Luis Enrique Sucar, ``Probabilistic Graphical Models - Principles
   and Applications'', Advances in Computer Vision and Pattern
   Recognition, Springer, 2015.
2. Kiran R Karkera, ``Building Probabilistic Graphical Models with
   Python'', Packt Publishing, 2014.
#+begin_comment
1. David Barber, ``Bayesian Reasoning and Machine Learning'',
   Cambridge University Press, 2020.  -unit 1,3,4,5
2. Daphne Koller, Nir Friedman, ``Probabilistic Graphical Models -
   Principles and Technique'', MIT Press, 2007.  unit -2
#+end_comment


** CO TO PO/PSO MAPPING
| PO/PSO | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | 11 | 12 | 1 | 2 | 3 |
|--------+---+---+---+---+---+---+---+---+---+----+----+----+---+---+---|
| CO1    | 2 | 1 | 1 | 0 | 0 | 0 | 0 | 0 | 0 |  0 |  0 |  0 | 1 | 0 | 0 |
| CO2    | 3 | 3 | 3 | 1 | 1 | 0 | 0 | 0 | 1 |  1 |  0 |  1 | 3 | 0 | 0 |
| CO3    | 3 | 3 | 3 | 1 | 1 | 0 | 0 | 0 | 1 |  1 |  0 |  1 | 3 | 0 | 0 |
| CO4    | 3 | 3 | 3 | 1 | 1 | 0 | 0 | 0 | 1 |  1 |  0 |  1 | 3 | 0 | 0 |
| CO5    | 2 | 3 | 3 | 0 | 0 | 0 | 0 | 0 | 0 |  0 |  0 |  1 | 1 | 0 | 0 |
| CO6    | 3 | 3 | 3 | 2 | 2 | 1 | 1 | 1 | 3 |  3 |  0 |  1 | 3 | 2 | 2 |
|--------+---+---+---+---+---+---+---+---+---+----+----+----+---+---+---|
| Course | 3 | 3 | 3 | 1 | 1 | 1 | 1 | 1 | 1 |  1 |  0 |  1 | 3 | 1 | 1 |

# | Score          | 16 | 16 | 16 | 5 | 5 | 1 | 1 | 1 | 6 |  6 |  0 |  5 | 14 | 2 | 2 |
