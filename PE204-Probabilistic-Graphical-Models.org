* 
:properties:
:author: Dr.R.S.Milton, Ms.S.Rajalakshmi
:date: 29.3.21
:end:

#+startup: showall
{{{title-tab}}}
| CODE    | COURSE TITLE                   | L | T | P | E | C |
| UCS2623 | PROBABILISTIC GRAPHICAL MODELS | 3 | 0 | 0 | 0 | 3 |

** R2021 CHANGES :noexport:
- New Subject
- co-po mapping added
- soft po added

** COURSE OBJECTIVES
- To learn the key aspects of directed and undirected models
- To apply the techniques to represent the model, do inference and learning
- To understand the methods for learning in hidden data.

{{{unit}}}
|UNIT I | INTRODUCTION| 9 |
Probabilistic Reasoning: Conditional Probability -- Probability Tables
-- Prior, Likelihood and Posterior; Graph Concept; Belief Networks:
Benefits of structure -- Uncertain and Unreliable Evidence -- Belief
concepts -- Causality.

{{{unit}}}
|UNIT II | REPRESENTATION IN GRAPHICAL MODELS | 9 |
Bayesian Network Representation: Independence properties --
Independence in graphs -- From distributions to graphs; Undirected
Graphical Models: Parameterization -- Markov Network Independencies --
Bayesian networks and Markov networks -- Partially directed models.

{{{unit}}}
|UNIT III | INFERENCE IN GRAPHICAL MODELS | 9 |
Efficient Inference in Trees: Marginal Inference -- Forms of Inference
-- Inference in Multiply Connected Graphs; Junction Tree Algorithm:
Clustering variables -- Clique graphs -- Junction trees --
Constructing junction trees for singly-Connected Distributions --
Junction Trees for Multiply-Connected Distributions -- Junction Tree
Algorithm; Making Decisions: Expected Utility -- Extending Bayesian
Networks for Decisions -- Solving Influence Diagrams -- Markov
Decision Processes -- Variational Inference and Planning.

{{{unit}}}
|UNIT IV | LEARNING IN PROBABILISTIC MODELS | 9 |
Statistics for Machine Learning: Representing Data -- Distributions --
Multivariate Gaussian -- Conjugate priors -- Properties of Maximum
Likelihood -- Learning a Gaussian; Learning as Inference: Bayesian
methods -- Maximum Likelihood Training of Belief Networks -- Bayesian
Belief Network Training -- Structure learning -- Maximum Likelihood
for Undirected models; Naive Bayes: Conditional Independence --
Estimation using Maximum Likelihood -- Bayesian Naive Bayes -- Tree
Augmented Naive Bayes.

{{{unit}}}
|UNIT V | LEARNING IN HIDDEN ENVIRONMENT | 9 |
Learning with Hidden Variables: Hidden Variables and Missing Data --
Expectation Maximisation -- Extensions of EM -- Variational Bayes;
Bayesian Model Selection: Comparing Models the Bayesian Way -- Occamâ€™s
Razor and Bayesian Complexity Penalisation -- Approximating the Model
Likelihood -- Bayesian Hypothesis Testing for Outcome Analysis.


** COURSE OUTCOMES
Upon completion of the course, the student should be able to
1. Explain the need for probabilistic graphical models (K2)
2. Apply various representations like directed and undirected models (K3)
3. Select inference algorithms for graphical models (K3)
4. Apply techniques to learn the structure and parameters in models (K3)
5. Outline the learning techniques for hidden data (K2)

      
** TEXT BOOKS
1. David Barber, ``Bayesian Reasoning and Machine Learning'',
   Cambridge University Press, 2020. 
2. Daphne Koller, Nir Friedman, ``Probabilistic Graphical Models -
   Principles and Technique'', MIT Press, 2007. 

** REFERENCES
1. Luis Enrique Sucar, ``Probabilistic Graphical Models - Principles
   and Applications'', Advances in Computer Vision and Pattern
   Recognition, Springer, 2015.
2. Kiran R Karkera, ``Building Probabilistic Graphical Models with
   Python'', Packt Publishing, 2014.
#+begin_comment
1. David Barber, ``Bayesian Reasoning and Machine Learning'',
   Cambridge University Press, 2020.  -unit 1,3,4,5
2. Daphne Koller, Nir Friedman, ``Probabilistic Graphical Models -
   Principles and Technique'', MIT Press, 2007.  unit -2
#+end_comment


** CO PO/PSO MAPPING
| PO/PSO |  1 |  2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | 11 | 12 |  1 | 2 |
|--------+----+----+---+---+---+---+---+---+---+----+----+----+----+---|
| CO1    |  3 |  2 |   |   |   |   |   |   |   |    |    |    |  2 |   |
| CO2    |  3 |  2 |   |   |   |   |   |   |   |    |    |    |  2 |   |
| CO3    |  3 |  2 |   |   |   |   |   |   |   |    |    |    |  2 |   |
| CO4    |  3 |  2 |   | 3 |   |   |   |   |   |    |    |    |  2 |   |
| CO5    |  3 |  2 |   |   |   |   |   |   |   |    |    |    |  2 |   |
|--------+----+----+---+---+---+---+---+---+---+----+----+----+----+---|
| Score  | 15 | 10 |   | 3 |   |   |   |   |   |    |    |    | 10 |   |
| Course |  3 |  2 |   | 3 |   |   |   |   |   |    |    |    |  2 |   |
